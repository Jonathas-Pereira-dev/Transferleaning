# -*- coding: utf-8 -*-
"""Transferlearning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sKHHhRbZUyWWhjo6wLKOhWG9qDCzSSFO
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import os

#if using Theano with GPU
#os.environ["KERAS_BACKEND"] = "tensorflow"

import random
import numpy as np
import keras
import tensorflow_datasets as tfds
import tensorflow as tf
from tensorflow.keras import layers, models  # <--- Adiciona essa linha


import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow

from keras.preprocessing import image
from keras.applications.imagenet_utils import preprocess_input
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import Conv2D, MaxPooling2D
from keras.models import Model

# Carregar o Dataset Cats vs Dogs

dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)

train_ds = dataset['train']

# Dividir em treino (80%) e validação (20%)
train_size = int(0.8 * info.splits['train'].num_examples)
val_size = int(0.2 * info.splits['train'].num_examples)

train_ds = train_ds.take(train_size)
val_ds = dataset['train'].skip(train_size)

IMG_SIZE = (160, 160)  # recomendado para MobileNetV2

def format_image(image, label):
    image = tf.image.resize(image, IMG_SIZE)
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

train_ds = train_ds.map(format_image).shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)
val_ds = val_ds.map(format_image).batch(32).prefetch(tf.data.AUTOTUNE)

base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SIZE + (3,),
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False  # Congela os pesos da base

# Construção do modelo final
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.2),
    layers.Dense(1, activation='sigmoid')  # Saída binária (gato/cachorro)
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(train_ds,
                    validation_data=val_ds,
                    epochs=5)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc))

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Treino')
plt.plot(epochs_range, val_acc, label='Validação')
plt.legend(loc='lower right')
plt.title('Acurácia')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Treino')
plt.plot(epochs_range, val_loss, label='Validação')
plt.legend(loc='upper right')
plt.title('Perda')
plt.show()

base_model.trainable = True
fine_tune_at = 100  # descongela a partir desta camada
for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='binary_crossentropy',
              metrics=['accuracy'])

fine_tune_history = model.fit(train_ds,
                              validation_data=val_ds,
                              epochs=3)